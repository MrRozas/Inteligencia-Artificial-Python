{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"QO3W1mKwuZB7"},"source":["**MODELOS DE EMBEDDINGS BASADOS EN WORD2VEC**\n","\n","*John Atkinson*\n","\n","Este programa utiliza  crea y utiliza modelos de embeddings de lenguaje basado en mètodos del tipo Word2Vec.\n","\n","Primero, necesitamos instalar algunos paquetes:"]},{"cell_type":"code","metadata":{"id":"CfmS1KKiun1t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664077206784,"user_tz":180,"elapsed":19929,"user":{"displayName":"Mr Mario","userId":"09124757733858718329"}},"outputId":"e636685b-71eb-4118-8c2d-5866ca09934b"},"source":["!pip install spacy\n","!python -m spacy download es_core_news_sm"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.4.1)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.3.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.2)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.1.0)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.8)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.6.2)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.64.1)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.9.2)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.10.1)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.4)\n","Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.1.1)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.10)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.8)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.3)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.8.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.8)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n","2022-09-25 03:39:59.583362: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting es-core-news-sm==3.4.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.4.0/es_core_news_sm-3.4.0-py3-none-any.whl (12.9 MB)\n","\u001b[K     |████████████████████████████████| 12.9 MB 2.7 MB/s \n","\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from es-core-news-sm==3.4.0) (3.4.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (2.0.8)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (4.64.1)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (3.0.10)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (0.4.2)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (0.6.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (2.11.3)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (2.23.0)\n","Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (4.1.1)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (3.0.7)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (1.0.3)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (1.0.8)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (8.1.0)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (2.4.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (21.3)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (2.0.6)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (0.10.1)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (3.3.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (1.9.2)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (1.21.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (57.4.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (3.8.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (5.2.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (2.10)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (0.7.8)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->es-core-news-sm==3.4.0) (2.0.1)\n","Installing collected packages: es-core-news-sm\n","Successfully installed es-core-news-sm-3.4.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('es_core_news_sm')\n"]}]},{"cell_type":"markdown","metadata":{"id":"fZpOLHcVuo2o"},"source":["Montamos nuestro *Drive* donde se encuentra la carpeta CORPUS con documentos separados por tema:"]},{"cell_type":"code","metadata":{"id":"ew3Tgj9PuOjW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664077762828,"user_tz":180,"elapsed":2474,"user":{"displayName":"Mr Mario","userId":"09124757733858718329"}},"outputId":"2d668843-755b-4260-fc8c-a30ae09b7896"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","%cd /content/gdrive/MyDrive/CORPUS"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","[Errno 2] No such file or directory: '/content/gdrive/MyDrive/CORPUS'\n","/content\n"]}]},{"cell_type":"markdown","metadata":{"id":"7UdMswDzuwB7"},"source":["Debemos importar algunas bibliotecas  y utilitarios:"]},{"cell_type":"code","metadata":{"id":"n3ZXsaVjuwrC"},"source":["import es_core_news_sm\n","from string import punctuation\n","from gensim.models import Word2Vec, KeyedVectors\n","import numpy as np\n","import pandas as pd\n","import regex\n","from sklearn.model_selection import train_test_split\n","from scipy.spatial.distance import cosine\n","from sklearn.metrics.pairwise import cosine_similarity\n","import os\n","from spacy.lang.es.stop_words import STOP_WORDS\n","from string import punctuation\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TCdfEFEfvT7Q"},"source":["Primero, definimos la función **EntrenarModelo(oraciones,NombreModelo)**, que permite entrenar un modelo Word2Vec a partir de un conjunto de oraciones extraída desde un corpus. El modelo generado se graba en la carpeta **NombreModelo**. Asumimos que la ventaja de entrenamiento es 2 ($windows=2$) y que el número de dimensiones o tamaño del vector es 4 ($size=4$).\n","\n","Luego, definimos una función **CargarModelo(NombreModelo)**, que nos permitirá cargar un modelo cuando sea necesario.\n","\n","Note que no necesariamente debemos entrenar el modelo nosotros mismos. Podríamos cargar un modelo de embeddings que ya ha sido entrenado por alguien más."]},{"cell_type":"code","metadata":{"id":"xvDmFlnDwLE4"},"source":["def EntrenarModelo(oraciones,NombreModelo):\n","    model = Word2Vec(oraciones, size=4, window=2, min_count=1)\n","    model.save(NombreModelo)\n","    \n","def CargarModelo(NombreModelo):\n","   modelo = Word2Vec.load(NombreModelo)\n","   vocabulario = [term for term in modelo.wv.vocab]  \n","   return(modelo,vocabulario)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z-qH4YzKz-mg"},"source":["Además, necesitaremos una función **ObtenerEmbeddingOracion(modelo, oracion)**, que nos permitirá obtener el embedding (vector) de una oración desde un modelo entrenado. El embedding de una oración es simplemente el vector promedio de cada una de las palabras de la oración: "]},{"cell_type":"code","metadata":{"id":"5iOz77PFz88a"},"source":["def ObtenerEmbeddingOracion(modelo, oracion):\n","   Lista_vectores = []\n","   for w in Tokenizar(oracion):\n","       # Verificar que la palabra w exista en el modelo\n","       try:\n","           modelo.wv[w]\n","       except KeyError:\n","           continue\n","       # Obtener vector de la palabra\n","       vec = modelo.wv[w]\n","       Lista_vectores.append(vec)\n","   embedding_palabras = np.array(Lista_vectores)\n","   if (len(embedding_palabras) > 0):\n","        embedding_oracion = embedding_palabras.mean(axis=0)\n","   else:\n","        embedding_oracion = np.zeros(modelo.vector_size)\n","   return(embedding_oracion) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UZj5KFfkyQnX"},"source":["Ahora, utilizamos algunas funciones de preprocesamiento:"]},{"cell_type":"code","metadata":{"id":"EA-A89OTyiy1"},"source":["def PreProcesarOraciones(textos):\n","    texto_limpio = []\n","    for texto in textos:  \n","        if len(texto)!=0:\n","          texto = regex.sub(' +', ' ', texto)\n","          tokens = Tokenizar(texto)\n","          texto_limpio.append(tokens)\n","    return(texto_limpio)\n","\n","def Tokenizar(oracion):\n","    doc = nlp(oracion)\n","    tokens = [palabra.text for palabra in doc]\n","    return(tokens)\n","\n","def CrearCorpus(path):\n","  directorio = os.listdir(path)\n","  corpus = []\n","  doc_id = []  \n","  for filename  in directorio:\n","     texto = open(path+filename,'r',encoding=\"latin-1\").read()\n","     corpus.append(texto)\n","     doc_id.append(filename)\n","  return(corpus,doc_id)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["En caso de ser necesario definimos una función que permite convertir una lista a un diccionario, de modo de poder acceder por clave (y no por índice):"],"metadata":{"id":"Szvub8wifLU4"}},{"cell_type":"code","source":["def CrearDiccionario(lista,claves):\n","   dicc = {}\n","   for  v in range(0,len(claves)):\n","      dicc[claves[v]] = lista[v]\n","   return(dicc)"],"metadata":{"id":"-vqcwQ55fRBc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0tTIjw2vzFMG"},"source":["Ahora, ejecutamos nuestro programa principal con algunas incializaciones:"]},{"cell_type":"code","metadata":{"id":"FK34lW6izLAL"},"source":["PATH = \"deportes/\"\n","nlp          = es_core_news_sm.load()\n","corpus,docID = CrearCorpus(PATH)\n","oraciones    =  PreProcesarOraciones(corpus)\n","CorpusConClave  = CrearDiccionario(corpus,docID)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2DAyV3uSzSRv"},"source":["Entrenamos el modelo en base a las oraciones generadas previamente:"]},{"cell_type":"code","metadata":{"id":"uIh2CDtDzY_o"},"source":["EntrenarModelo(oraciones,'mi_word2vec')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ovHOhFoJzbEQ"},"source":["Luego, cargamos el modelo entrenado:"]},{"cell_type":"code","metadata":{"id":"NWBtEpdgzlYA"},"source":["modelo, vocabulario = CargarModelo('mi_word2vec')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Podemos, obtener el embedding de alguna palabra:"],"metadata":{"id":"m3OglWudfpPk"}},{"cell_type":"code","source":["print(modelo.wv['jugador'])"],"metadata":{"id":"t6bPS6x9cCCJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y-fqrq_W0sFw"},"source":["Una vez que tenemos nuestro modelo cargado, podemos realizar diferentes tareas sobre los vectores de palabras u oraciones.\n","\n","Por ejemplo, podemos determinar la *cercanía* entre dos documentos del corpus. Para ello:\n","\n","1.   Tomamos el texto de cada documento.\n","2.   Obtenemos sus respectivos vectores (embeddings).\n","3.   Calculamos la distancia **coseno**."]},{"cell_type":"code","metadata":{"id":"oDnDZgBz56lD"},"source":["doc1 = CorpusConClave['d15.txt']\n","doc2 = CorpusConClave['d21.txt']\n","vec1 = ObtenerEmbeddingOracion(modelo, doc1)\n","vec2 = ObtenerEmbeddingOracion(modelo, doc2)\n","\n","similitud = 1-cosine(vec1,vec2)\n","print(similitud)"],"execution_count":null,"outputs":[]}]}